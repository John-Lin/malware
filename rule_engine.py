import re
import os
import logging
import time
from malware import utils
from malware.snort import SnortRule
from malware import pickle_tool
from malware import apikey
from virus_total_apis import PrivateApi as VirusTotal

logger = logging.getLogger(__name__)

request_times = 0
init_timer = time.time()


def list_pcap(path):
    for dirPath, dirNames, fileNames in os.walk(path):
        for f in fileNames:
            if f.split('.')[1] == 'pcap':
                yield os.path.join(dirPath, f)


def _check_timer_counter():
    global request_times
    global init_timer
    if request_times == 300:
        request_times = 0
        period = time.time() - init_timer
        waiting = 60 - period + 1
        if waiting > 0:
            logger.info("Waiting %s seconds", (str(waiting)))
            time.sleep(waiting)
        init_timer = time.time()


def is_valid_url(url):
    import re
    regex = re.compile(
        # r'^(?:[a-z0-9\.\-]*)://'  # scheme is validated separately
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}(?<!-)\.?)|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|'  # ...or ipv4
        r'\[?[A-F0-9]*:[A-F0-9:]+\]?)'  # ...or ipv6
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return url is not None and regex.search(url)


def get_url_positive(resource, cache={}):
    if resource in cache.keys():
        # logger.info("%s in cache" % resource)
        positives = cache.get(resource)
        # logger.info('%s in cache positives: %s' % (resource, positives))
        return positives
    else:
        global request_times
        global init_timer
        request_times += 1
        logger.info("Search on VirusTotal counter: %s", str(request_times))
        vt = VirusTotal(apikey.APIKEY_0)
        positives = vt.get_url_report(resource).get('results').get('positives')
        _check_timer_counter()

        if positives >= 0:
            cache[resource] = positives
            return positives
        elif positives is None:
            logger.info("No report. Submmit the URL to VirusTotal")
            vt.scan_url(resource)
            _check_timer_counter()
            return None
        else:
            logger.debug("Get reports failed.")
            return None


def iterpayload(path):
    connection = utils.follow_tcp_stream(path)
    for conn, frame in connection.iteritems():
        for seq, content in frame.iteritems():
            if content:
                # Generate the content and 5-tuple
                yield content, conn
            else:
                # Some packets have no payload
                pass


def gen_rule(pcap_path):
    # rule_set = list()
    cache = pickle_tool.check_json()
    # sid = 1000000
    for content, conn in iterpayload('%s' % (pcap_path)):
        # print content, utils.connection_key_2_str(conn)
        get_method = re.search('GET (.*) ', content)
        host = re.search('Host: (.*)', content)
        if host and get_method:
            # pos = get_positive(host.group(1).rstrip(), cache)
            # print host.group(1).rstrip()

            # if pos > 0:
            #     sid += 1
            #     rule = make_host_rule(host.group(0).rstrip(), conn[3])
            #     if not iscontent(rule, RULE):
            #        RULE.append(rule)
                # else:
                #     pass
                    # sid -= 1
            # else:
            #     pass
                # print "NOT generate"
                # NOT generate rule

            if get_method.group(1) == '/':
                url = is_valid_url(host.group(1).rstrip())
            else:
                url = is_valid_url(host.group(1).rstrip() + get_method.group(1))

            if url is not None:
                host_content = host.group(0).rstrip()
                uricontent = get_method.group(1)
                pos = get_url_positive(url.group(0), cache)

            if pos > 0:
                # print "BAD URL: %s" % uricontent
                if uricontent == '/':
                    uricontent = None
                rule = make_uri_rule(host_content, uricontent, conn[3])
                with open('uricontent.rules', 'a') as fp:
                    fp.write('{r}\n'.format(r=str(rule)))
                yield rule
            else:
                # positives == 0 or positives == None
                pass

        else:
            # print "no URL"
            pass
            # print repr(content)
    # for r in rule_set:
    #     print r
    pickle_tool.update_json(cache)
    # return rule_set


def make_host_rule(content, dst_port, sid=0):
    rule = SnortRule()
    pattern = dict()
    pattern['msg'] = '"Trojan.Gen"'
    pattern['content'] = ['"{host}"'.format(host=content), 'nocase']
    # pattern['sid'] = sid
    pattern['dst_port'] = dst_port
    rule.set_malicious_pattern(**pattern)
    return rule


def make_uri_rule(content, uricontent, dst_port, sid=0):
    rule = SnortRule()
    pattern = dict()
    pattern['msg'] = '"Trojan.Gen.uricontent"'
    pattern['content'] = ['"{host}"'.format(host=content), 'nocase']
    pattern['uricontent'] = ['"{uri}"'.format(uri=uricontent), 'nocase']
    # pattern['sid'] = sid
    pattern['dst_port'] = dst_port
    rule.set_malicious_pattern(**pattern)
    return rule


def main():
    logging.basicConfig(level=logging.INFO,
                        format='[%(levelname)s] %(message)s',)

    rule_instances = list()
    RULE = list()

    for pcap in list_pcap('./PCAPLog/'):
        for rule in gen_rule(pcap):
            rule_instances.append(rule)

    for ruleobj in rule_instances:
        RULE.append(str(ruleobj))

    RULE = list(set(RULE))

    for r in RULE:
        print r


if __name__ == "__main__":
    main()
