import re
import sys
import os
import logging
import time
import hashlib
from urlparse import urlparse
from malware import utils
from malware.snort import SnortRule
from malware.sql_tool import SQLiteTool
from malware import apikey
from virus_total_apis import PrivateApi as VirusTotal

logger = logging.getLogger(__name__)

REQUEST_RATE = 300
APIKEY = apikey.APIKEY_0


class RuleEngineBase(object):
    def __init__(self, path='./PCAPLog/'):
        self.rules = list()
        self._db = SQLiteTool()
        self._db.creat()
        self.paylpad_iter = PayloadIterator2(path)
        self.vd = Validator()
        self.vt = VirusTotal(APIKEY)
        self.cache = {}

    def _make_rule(self, **kwargs):
        rule = SnortRule()
        pattern = dict()
        pattern['msg'] = '"Trojan.Gen"'

        content = kwargs.get('content')
        uricontent = kwargs.get('uricontent')
        dst_port = kwargs.get('dst_port')
        md5 = kwargs.get('md5')

        if content is not None:
            pattern['content'] = ['"{host}"'.format(host=content), 'nocase']
        if uricontent is not None and uricontent != '/':
            pattern['uricontent'] = ['"{uri}"'.format(uri=uricontent), 'nocase']
        if md5 is not None:
            pattern['reference'] = ['md5, {m}'.format(m=md5)]
        # pattern['sid'] = sid
        pattern['dst_port'] = dst_port
        rule.set_malicious_pattern(**pattern)
        self.rules.append(rule)
        self._log_rules(rule, md5)

    def _get_url_positive(self, resource):
        urlkey = hashlib.sha1(resource).hexdigest()

        if self._db.is_url(urlkey):
            # print "In Table!!"
            return self._db.show_positive(urlkey)

    def _log_rules(self, data, filename):
        # print str(data)
        if not os.path.exists('./rules'):
            os.makedirs('./rules')

        with open('./rules/{m}_rule.rules'.format(m=filename), 'a') as fp:
            fp.write('{r}\n'.format(r=str(data)))

class RuleEngineOnline(RuleEngineBase):
    def __init__(self):
        self.vt_req_counter = 0
        self.vt_req_timer = time.time()
        super(RuleEngineOnline, self).__init__()

    def _check_timer_counter(self):
        if self.vt_req_counter == REQUEST_RATE:
            self.vt_req_counter = 0
            period = time.time() - self.vt_req_timer
            waiting = 60 - period + 1
            if waiting > 0:
                logger.info("Waiting %s seconds", (str(waiting)))
                time.sleep(waiting)
            self.vt_req_timer = time.time()

    def _make_rule(self, **kwargs):
        super(RuleEngineOnline, self)._make_rule(**kwargs)

    def _get_url_positive(self, resource):
        urlkey = hashlib.sha1(resource).hexdigest()

        if self._db.is_url(urlkey):
            # print "In Table!!"
            # ================== Updated the Database URL column ===============
            self._check_timer_counter()
            self.vt_req_counter += 1
            response = self.vt.get_url_report(resource)
            if response.get('error') is not None:
                logger.info("Error: {e}".format(e=response.get('error')))
                return None
                # sys.exit(0)

            results = response.get('results')
            positives = results.get('positives')
            url = results.get('url')

            if positives >= 0:
                # self.cache[urlkey] = [resource, positives]
                self._db.insert2(urlkey, url, positives)
            # ================== Updated the Database URL column ===============
            return self._db.show_positive(urlkey)
        else:
            self._check_timer_counter()
            self.vt_req_counter += 1
            logger.info("Search on VirusTotal counter: %s",
                        str(self.vt_req_counter))
            logger.info(resource)
            response = self.vt.get_url_report(resource)

            if response.get('error') is not None:
                logger.info("Error: {e}".format(e=response.get('error')))
                return None
                # sys.exit(0)

            results = response.get('results')
            positives = results.get('positives')
            url = results.get('url')

            if positives >= 0:
                # self.cache[urlkey] = [resource, positives]
                self._db.insert2(urlkey, url, positives)
                # self._db.insert2(url_id, url, positives)
                return positives
            elif positives is None:
                self._check_timer_counter()
                self.vt_req_counter += 1
                logger.info('''No report. Submmit the URL to VirusTotal countert: %s''',
                            str(self.vt_req_counter))
                self.vt.scan_url(resource)
                return None
            else:
                logger.debug("Get reports failed.")
                return None

    def generate(self):
        for content, conn, filename in self.paylpad_iter:
            try:
                get_obj = self.vd.is_get_method(content)
                host_obj = self.vd.is_hsot(content)
                if host_obj and get_obj:
                    uri = get_obj.group(1)
                    host_field = host_obj.group(1).rstrip()
                    o = urlparse('http://'+ host_field + uri)
                    # domian = o.netloc
                    # uri = o.path
                    if o.path != '/':
                        string = self.vd.is_valid_utf8(host_field + uri)
                        if string is None:
                            return

                        url_obj = self.vd.is_valid_url(string)
                        if url_obj is None:
                            return

                        url_pos = self._get_url_positive(url_obj.group(0))
                        if url_pos > 0:
                            self._make_rule(content=host_obj.group(0).rstrip(),
                                            uricontent=o.path,
                                            dst_port=conn[3],
                                            md5=filename.split('.')[0])
                        else:
                            # positive == 0
                            pass
                    else:
                        pass
                        # o.path == '/'
                        # Proberbly an malicious domain name

                    # domain_pos = self._get_url_positive(o.netloc)
                    # # TODO
                    # # domain_pos = self._get_domain_positive(host_field)
                    # if domain_pos > 0:
                    #     self._make_rule(content=host_obj.group(0).rstrip(),
                    #                     dst_port=conn[3],
                    #                     md5=filename.split('.')[0])
                    # else:
                    #     # positive == 0
                    #     pass

                    # host_content = host_obj.group(0).rstrip()
                    # if uri == '/':
                    #     # Only Domain name
                    #     # domain == host_field
                    #     # d = self.vd.is_valid_utf8(host_field)
                    #     domain = host_field
                    #     domain_pos = self._get_url_positive(host_field)
                    #     # TODO
                    #     # domain_pos = self._get_domain_positive(host_field)
                    #     if domain_pos > 0:
                    #         # make content rules
                    #         self._make_rule(content=host_content,
                    #                         dst_port=conn[3],
                    #                         md5=filename.split('.')[0])
                    # else:
                    #     print('Domain + URI == URL')
                    #     # Domain + URI == URL
                    #     url = host_field + uri
                    #     # u = self.vd.is_valid_utf8(url)
                    #     url_obj = self.vd.is_valid_url(url)
                    #     if url_obj is None:
                    #         return
                    #     url_pos = self._get_url_positive(url)
                    #     if url and url_pos > 0:
                    #         # make content and uri rules
                    #         self._make_rule(content=host_content,
                    #                         uricontent=get_obj.group(1),
                    #                         dst_port=conn[3],
                    #                         md5=filename.split('.')[0])
                else:
                    pass
            except KeyboardInterrupt:
                logger.info("Quit")
                sys.exit()
            # try:
            #     # print utils.connection_key_2_str(conn), filename
            #     # print content, utils.connection_key_2_str(conn)
            #     get_method = self.vd.is_get_method(content)
            #     host = self.vd.is_hsot(content)
            #     if host and get_method:
            #         if get_method.group(1) == '/':
            #             # Domain name
            #             url = self.vd.is_valid_url(host.group(1).rstrip())
            #         else:
            #             url = self.vd.is_valid_url(host.group(1).rstrip() +
            #                                        get_method.group(1))
            #
            #         # print url
            #         if url is not None:
            #             url = self.vd.is_valid_utf8(url.group(0))
            #
            #         if url is not None:
            #             host_content = host.group(0).rstrip()
            #             uricontent = get_method.group(1)
            #             pos = self._get_url_positive(url)
            #             if pos > 0:
            #                 if uricontent == '/':
            #                     uricontent = None
            #                 # print host_content
            #                 self._make_rule(content=host_content,
            #                                 uricontent=uricontent,
            #                                 dst_port=conn[3],
            #                                 md5=filename.split('.')[0])
            #                 # yield rule
            #             else:
            #                 # positives == 0 or positives == None
            #                 pass
            #         else:
            #             # invalid_url
            #             pass
            #     else:
            #         pass
            # except KeyboardInterrupt:
            #     logger.info("Quit")
            #     sys.exit()

    def _log_rules(self, data, filename):
        super(RuleEngineOnline, self)._log_rules(data, filename)

class RuleEngineOffline(RuleEngineBase):
    def __init__(self):
        super(RuleEngineOffline, self).__init__()

    def _make_rule(self, **kwargs):
        super(RuleEngineOnline, self)._make_rule(**kwargs)
    def _get_url_positive(self, resource):
        super(RuleEngineOffline, self)._get_url_positive()

    def _log_rules(self, rule):
        super(RuleEngineOnline, self)._log_rules(rule)

    def generate(self):
        self.cache = pickle_tool.check_json()
        if not self.cache:
            print "Nothing can generate"
            sys.exit()
        for key, value in self.cache.iterms():
            if value[1] > 0:
                pass
                # TODO:
                # 1: JSON need to save uricontent, content
                # 2: Reconstruct the snort rule
                # get_method = self.vd.is_get_method(content)
                # host = self.vd.is_valid_url(content)
                # self._make_rule(content=, uricontent=, dst_port=80)

class Validator(object):
    def __init__(self):
        pass

    def is_valid_url(self, url):
        regex = re.compile(
            # r'^(?:[a-z0-9\.\-]*)://'  # scheme is validated separately
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}(?<!-)\.?)|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|'  # ...or ipv4
            r'\[?[A-F0-9]*:[A-F0-9:]+\]?)'  # ...or ipv6
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        return url is not None and regex.search(url)

    def is_valid_domain_name(self, domain_name):
        # TODO
        # Valid domain names
        # ex: syshell.exe is not domain
        # regex = re.compile(r'[a-zA-Z\d-]{,63}(\.[a-zA-Z\d-]{,63})*',
        #                    re.IGNORECASE)
        # return domain_name is not None and regex.search(domain_name)
        # return domain_name
        pass

    def is_hsot(self, content):
        regex = re.compile('Host: (.*)')
        return content is not None and regex.search(content)

    def is_get_method(self, content):
        regex = re.compile('GET (.*) ')
        return content is not None and regex.search(content)

    def is_valid_utf8(self, data):
        # valid_utf8 = True
        try:
            data.decode('utf-8')
            # return data
        except UnicodeDecodeError:
            with open('invalid_utf8.log', 'a') as fp:
                fp.write('{u}\n'.format(u=data))
            data = None
        return data
            # valid_utf8 = False


class PayloadIterator2(object):
    def __init__(self, path):
        self.index = 0
        self.path = path
        self.pcap_list = list()
        self.content = list()
        self.five_tuple = list()
        self.file_pointer = list()

    def __iter__(self):
        for dirPath, dirNames, fileNames in os.walk(self.path):
            for f in fileNames:
                if f.split('.')[1] == 'pcap':
                    self.pcap_list.append(os.path.join(dirPath, f))
                else:
                    # Not a pcap file
                    pass

        for p in self.pcap_list:
            connection = utils.follow_tcp_stream(p)
            for five_tuple, frame in connection.iteritems():
                for seq, content in frame.iteritems():
                    if content:
                        # Generate the content and 5-tuple
                        self.content.append(content)
                        self.five_tuple.append(five_tuple)
                        self.file_pointer.append(p.split('/')[-1])
                    else:
                        # Some packets have no payload
                        pass
        logger.info("Total Pcap file: %s", str(len(set(self.file_pointer))))
        logger.info("Total Connections : %s", str(len(set(self.five_tuple))))
        return self

    def next(self):
        try:
            five_tuple = self.five_tuple[self.index]
            content = self.content[self.index]
            file_pointer = self.file_pointer[self.index]
        except IndexError:
            raise StopIteration
        self.index += 1
        return content, five_tuple, file_pointer


def main():
    logging.basicConfig(level=logging.INFO,
                        format='[%(levelname)s] %(message)s',)
    rules = list()

    rule_engine = RuleEngineOnline()
    rule_engine.generate()
    # print dir(rule_engine)

    for ruleobj in rule_engine.rules:
        rules.append(str(ruleobj))

    rules = list(set(rules))

    for r in rules:
        print r
        with open('main_snort.rules', 'a') as fp:
            fp.write(r + '\n')

if __name__ == "__main__":
    main()
