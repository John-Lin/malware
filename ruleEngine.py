import re
import sys
import os
import logging
import time
import hashlib
from malware import utils
from malware.snort import SnortRule
from malware import sql_tool
from malware import apikey
from virus_total_apis import PrivateApi as VirusTotal

logger = logging.getLogger(__name__)

REQUEST_RATE = 300
APIKEY = apikey.APIKEY_0


class RuleEngineBase(object):
    def __init__(self, path='./PCAPLog/'):
        self.rules = list()
        self._db = sql_tool.SQLiteTool()
        self._db.creat()
        self.paylpad_iter = PayloadIterator2(path)
        self.vd = Validator()
        self.vt = VirusTotal(APIKEY)
        self.cache = {}

    def _make_rule(self, **kwargs):
        rule = SnortRule()
        pattern = dict()
        pattern['msg'] = '"Trojan.Gen"'

        content = kwargs.get('content')
        uricontent = kwargs.get('uricontent')
        dst_port = kwargs.get('dst_port')
        md5 = kwargs.get('md5')

        if content is not None:
            pattern['content'] = ['"{host}"'.format(host=content), 'nocase']
        if uricontent is not None:
            pattern['uricontent'] = ['"{uri}"'.format(uri=uricontent), 'nocase']
        if md5 is not None:
            pattern['reference'] = ['md5, {m}'.format(m=md5)]
        # pattern['sid'] = sid
        pattern['dst_port'] = dst_port
        rule.set_malicious_pattern(**pattern)
        self.rules.append(rule)
        self._log_rules(rule, md5)

    def _get_url_positive(self, resource):
        urlkey = hashlib.sha1(resource).hexdigest()

        if self._db.is_url(urlkey):
            # print "In Table!!"
            return self._db.show_positive(urlkey)

    def _log_rules(self, data, filename):
        # print str(data)
        if not os.path.exists('./rules'):
            os.makedirs('./rules')

        with open('./rules/{m}_rule.rules'.format(m=filename), 'a') as fp:
            fp.write('{r}\n'.format(r=str(data)))

class RuleEngineOnline(RuleEngineBase):
    def __init__(self):
        self.vt_req_counter = 0
        self.vt_req_timer = time.time()
        super(RuleEngineOnline, self).__init__()

    def _check_timer_counter(self):
        if self.vt_req_counter == REQUEST_RATE:
            self.vt_req_counter = 0
            period = time.time() - self.vt_req_timer
            waiting = 60 - period + 1
            if waiting > 0:
                logger.info("Waiting %s seconds", (str(waiting)))
                time.sleep(waiting)
            self.vt_req_timer = time.time()

    def _make_rule(self, **kwargs):
        super(RuleEngineOnline, self)._make_rule(**kwargs)

    def _get_url_positive(self, resource):
        urlkey = hashlib.sha1(resource).hexdigest()

        if self._db.is_url(urlkey):
            # print "In Table!!"
            return self._db.show_positive(urlkey)
        else:
            self._check_timer_counter()
            self.vt_req_counter += 1
            logger.info("Search on VirusTotal counter: %s",
                        str(self.vt_req_counter))

            response = self.vt.get_url_report(resource)

            if response.get('error') is not None:
                logger.info("Error: {e}".format(e=response.get('error')))
                return None
                # sys.exit(0)

            results = response.get('results')
            positives = results.get('positives')

            if positives >= 0:
                # self.cache[urlkey] = [resource, positives]
                self._db.insert2(urlkey, resource, positives)
                return positives
            elif positives is None:
                self._check_timer_counter()
                self.vt_req_counter += 1
                logger.info('''No report. Submmit the URL to VirusTotal countert: %s''',
                            str(self.vt_req_counter))
                self.vt.scan_url(resource)
                return None
            else:
                logger.debug("Get reports failed.")
                return None

    def generate(self):
        # self.cache = pickle_tool.check_json()
        for content, conn, filename in self.paylpad_iter:
            try:
                # print utils.connection_key_2_str(conn), filename
                # print content, utils.connection_key_2_str(conn)
                get_method = self.vd.is_get_method(content)
                host = self.vd.is_hsot(content)
                if host and get_method:
                    if get_method.group(1) == '/':
                        url = self.vd.is_valid_url(host.group(1).rstrip())
                    else:
                        url = self.vd.is_valid_url(host.group(1).rstrip() +
                                                   get_method.group(1))

                    if url is not None:
                        url = self.vd.is_valid_utf8(url)

                    if url is not None:
                        host_content = host.group(0).rstrip()
                        uricontent = get_method.group(1)
                        pos = self._get_url_positive(url.group(0))
                        if pos > 0:
                            if uricontent == '/':
                                uricontent = None
                            #print host_content
                            self._make_rule(content=host_content,
                                            uricontent=uricontent,
                                            dst_port=conn[3],
                                            md5=filename.split('.')[0])
                            # yield rule
                        else:
                            # positives == 0 or positives == None
                            pass
                    else:
                        # invalid_url
                        pass
                else:
                    pass
            except KeyboardInterrupt:
                logger.info("Quit")
                sys.exit()

        # pickle_tool.update_json(self.cache)

    def _log_rules(self, data, filename):
        super(RuleEngineOnline, self)._log_rules(data, filename)

class RuleEngineOffline(RuleEngineBase):
    def __init__(self):
        super(RuleEngineOffline, self).__init__()

    def _make_rule(self, **kwargs):
        super(RuleEngineOnline, self)._make_rule(**kwargs)
    def _get_url_positive(self, resource):
        super(RuleEngineOffline, self)._get_url_positive()

    def _log_rules(self, rule):
        super(RuleEngineOnline, self)._log_rules(rule)

    def generate(self):
        self.cache = pickle_tool.check_json()
        if not self.cache:
            print "Nothing can generate"
            sys.exit()
        for key, value in self.cache.iterms():
            if value[1] > 0:
                pass
                # TODO:
                # 1: JSON need to save uricontent, content
                # 2: Reconstruct the snort rule
                # get_method = self.vd.is_get_method(content)
                # host = self.vd.is_valid_url(content)
                # self._make_rule(content=, uricontent=, dst_port=80)

class Validator(object):
    def is_valid_url(self, url):
        regex = re.compile(
            # r'^(?:[a-z0-9\.\-]*)://'  # scheme is validated separately
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}(?<!-)\.?)|'  # domain...
            r'localhost|'  # localhost...
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|'  # ...or ipv4
            r'\[?[A-F0-9]*:[A-F0-9:]+\]?)'  # ...or ipv6
            r'(?::\d+)?'  # optional port
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        return url is not None and regex.search(url)

    def is_hsot(self, content):
        regex = re.compile('Host: (.*)')
        return content is not None and regex.search(content)

    def is_get_method(self, content):
        regex = re.compile('GET (.*) ')
        return content is not None and regex.search(content)

    def is_valid_utf8(self, url):
        # valid_utf8 = True
        try:
            url.group(0).decode('utf-8')
            return url
        except UnicodeDecodeError:
            with open('invalid_utf8', 'a') as fp:
                fp.write('{u}\n'.format(u=url.group(0)))
            url = None
            return url
            # valid_utf8 = False


class PayloadIterator2(object):
    def __init__(self, path):
        self.index = 0
        self.path = path
        self.pcap_list = list()
        self.content = list()
        self.five_tuple = list()
        self.file_pointer = list()

    def __iter__(self):
        for dirPath, dirNames, fileNames in os.walk(self.path):
            for f in fileNames:
                if f.split('.')[1] == 'pcap':
                    self.pcap_list.append(os.path.join(dirPath, f))
                else:
                    # Not a pcap file
                    pass

        for p in self.pcap_list:
            connection = utils.follow_tcp_stream(p)
            for five_tuple, frame in connection.iteritems():
                for seq, content in frame.iteritems():
                    if content:
                        # Generate the content and 5-tuple
                        self.content.append(content)
                        self.five_tuple.append(five_tuple)
                        self.file_pointer.append(p.split('/')[-1])
                    else:
                        # Some packets have no payload
                        pass
        logger.info("Total Pcap file: %s", str(len(set(self.file_pointer))))
        logger.info("Total Connections : %s", str(len(set(self.five_tuple))))
        return self

    def next(self):
        try:
            five_tuple = self.five_tuple[self.index]
            content = self.content[self.index]
            file_pointer = self.file_pointer[self.index]
        except IndexError:
            raise StopIteration
        self.index += 1
        return content, five_tuple, file_pointer


def main():
    logging.basicConfig(level=logging.INFO,
                        format='[%(levelname)s] %(message)s',)
    rules = list()

    rule_engine = RuleEngineOnline()
    rule_engine.generate()
    # print dir(rule_engine)

    for ruleobj in rule_engine.rules:
        rules.append(str(ruleobj))

    rules = list(set(rules))

    for r in rules:
        print r
        with open('main_snort.rules', 'a') as fp:
            fp.write(r + '\n')

if __name__ == "__main__":
    main()
